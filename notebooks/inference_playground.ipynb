{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softdrawart/Vtoonify/blob/main/notebooks/inference_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg7EfmBZzwMM"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/williamyang1991/VToonify/blob/master/notebooks/inference_playground.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab contains three parts\n",
        "\n",
        "\n",
        "- **PART1**: Build a web demo with Gradio UI for easy use\n",
        "  - Easy Uploading of your own photo or video\n",
        "  - Easy loading of pre-trained model\n",
        "  - Just click the button to toonify\n",
        "  - The pretrained model will be downloaded from HuggingFace model\n",
        "  - This part is independent of the following two parts.\n",
        "- **PART2**: Style tranfer with Colab UI where you can look into the code details and easily modify the code\n",
        "  - The pretrained model will be downloaded from Google Drive\n",
        "- **PART3**: Style control with Colab UI where you can look into the code details and easily modify the code\n",
        "  - The pretrained model will be downloaded from Google Drive"
      ],
      "metadata": {
        "id": "qPGiB9946Uze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART I - Style Transfer with Gradio UI\n"
      ],
      "metadata": {
        "id": "3FthlHXKfd0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio huggingface_hub"
      ],
      "metadata": {
        "id": "ZLdS57vYfo1f",
        "outputId": "619dd9d0-518f-448f-b471-9b6e630eb5be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "os.chdir('../')\n",
        "DEMO_DIR = 'VToonify_Gradio'\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "DLpxP-Ge8pwB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/spaces/PKUWilliamYang/VToonify $DEMO_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S36V17c8zYo",
        "outputId": "b2195ae4-1f95-4ca7-ff60-2be5aa2a5dbf",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VToonify_Gradio'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (367/367), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 367 (delta 172), reused 367 (delta 172), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (367/367), 3.17 MiB | 3.60 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "Encountered 6 file(s) that should have been pointers, but weren't:\n",
            "\tvtoonify/model/stylegan/lpips/weights/v0.0/alex.pth\n",
            "\tvtoonify/model/stylegan/lpips/weights/v0.0/squeeze.pth\n",
            "\tvtoonify/model/stylegan/lpips/weights/v0.0/vgg.pth\n",
            "\tvtoonify/model/stylegan/lpips/weights/v0.1/alex.pth\n",
            "\tvtoonify/model/stylegan/lpips/weights/v0.1/squeeze.pth\n",
            "\tvtoonify/model/stylegan/lpips/weights/v0.1/vgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(f'./{DEMO_DIR}')"
      ],
      "metadata": {
        "id": "H5GZdb5x9Db5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import pathlib\n",
        "import gradio as gr\n",
        "from vtoonify_model import Model\n",
        "\n",
        "def update_slider(choice: str) -> dict:\n",
        "    if type(choice) == str and choice.endswith('-d'):\n",
        "        return gr.update(maximum=1, minimum=0, value=0.5)\n",
        "    else:\n",
        "        return gr.update(maximum=0.5, minimum=0.5, value=0.5)\n",
        "\n",
        "def set_example_image(example: list) -> dict:\n",
        "    return gr.update(value=example[0])\n",
        "\n",
        "def set_example_video(example: list) -> dict:\n",
        "    return gr.Video.update(value=example[0]),\n",
        "\n",
        "sample_video = ['./vtoonify/data/529_2.mp4','./vtoonify/data/7154235.mp4','./vtoonify/data/651.mp4','./vtoonify/data/908.mp4']\n",
        "sample_vid = gr.Video(label='Video file')  #for displaying the example\n",
        "example_videos = gr.components.Dataset(components=[sample_vid], samples=[[path] for path in sample_video], type='values', label='Video Examples')\n",
        "\n",
        "model = Model('cuda')\n",
        "\n",
        "# if you would like to run long videos, set model.video_limit_gpu to a large value\n",
        "model.video_limit_gpu = 1000000   # currently we don't have limitation on the frames with GPU\n",
        "model.video_limit_cpu = 100   # currently we only toonify 100 frames per video with CPU"
      ],
      "metadata": {
        "id": "I99dpdo1ft71",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DESCRIPTION = '''\n",
        "<div align=center>\n",
        "<h1 style=\"font-weight: 900; margin-bottom: 7px;\">\n",
        "   Portrait Style Transfer with <a href=\"https://github.com/williamyang1991/VToonify\">VToonify</a>\n",
        "</h1>\n",
        "</div>\n",
        "'''\n",
        "FOOTER = '<div align=center><img id=\"visitor-badge\" alt=\"visitor badge\" src=\"https://visitor-badge.laobi.icu/badge?page_id=williamyang1991/VToonify\" /></div>'\n",
        "\n",
        "ARTICLE = r\"\"\"\n",
        "If VToonify is helpful, please help to ⭐ the <a href='https://github.com/williamyang1991/VToonify' target='_blank'>Github Repo</a>. Thanks!\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/williamyang1991/VToonify?style=social)](https://github.com/williamyang1991/VToonify)\n",
        "---\n",
        "📝 **Citation**\n",
        "If our work is useful for your research, please consider citing:\n",
        "```bibtex\n",
        "@article{yang2022Vtoonify,\n",
        "  title={VToonify: Controllable High-Resolution Portrait Video Style Transfer},\n",
        "  author={Yang, Shuai and Jiang, Liming and Liu, Ziwei and Loy, Chen Change},\n",
        "  journal={ACM Transactions on Graphics (TOG)},\n",
        "  volume={41},\n",
        "  number={6},\n",
        "  articleno={203},\n",
        "  pages={1--15},\n",
        "  year={2022},\n",
        "  publisher={ACM New York, NY, USA},\n",
        "  doi={10.1145/3550454.3555437},\n",
        "}\n",
        "```\n",
        "📋 **License**\n",
        "This project is licensed under <a rel=\"license\" href=\"https://github.com/williamyang1991/VToonify/blob/main/LICENSE.md\">S-Lab License 1.0</a>.\n",
        "Redistribution and use for non-commercial purposes should follow this license.\n",
        "📧 **Contact**\n",
        "If you have any questions, please feel free to reach me out at <b>williamyang@pku.edu.cn</b>.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "\n",
        "    with gr.Group():\n",
        "        gr.Markdown('''## Step 1(Select Style)\n",
        "- Select **Style Type**.\n",
        "    - Type with `-d` means it supports style degree adjustment.\n",
        "    - Type without `-d` usually has better toonification quality.\n",
        "''')\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown('''Select Style Type''')\n",
        "                with gr.Row():\n",
        "                    style_type = gr.Radio(label='Style Type',\n",
        "                                          choices=['cartoon1','cartoon1-d','cartoon2-d','cartoon3-d',\n",
        "                                                   'cartoon4','cartoon4-d','cartoon5-d','comic1-d',\n",
        "                                                   'comic2-d', 'arcane1','arcane1-d','arcane2', 'arcane2-d',\n",
        "                                                   'caricature1','caricature2','pixar','pixar-d',\n",
        "                                                   'illustration1-d', 'illustration2-d', 'illustration3-d', 'illustration4-d', 'illustration5-d',\n",
        "                                                  ]\n",
        "                                         )\n",
        "                    exstyle = gr.State()\n",
        "                with gr.Row():\n",
        "                    loadmodel_button = gr.Button('Load Model')\n",
        "                with gr.Row():\n",
        "                    load_info = gr.Textbox(label='Process Information', interactive=False, value='No model loaded.')\n",
        "            with gr.Column():\n",
        "                gr.Markdown('''Reference Styles\n",
        "![example](https://raw.githubusercontent.com/williamyang1991/tmpfile/master/vtoonify/style.jpg)''')\n",
        "\n",
        "\n",
        "    with gr.Group():\n",
        "        gr.Markdown('''## Step 2 (Preprocess Input Image / Video)\n",
        "- Drop an image/video containing a near-frontal face to the **Input Image**/**Input Video**.\n",
        "- Hit the **Rescale Image**/**Rescale First Frame** button.\n",
        "    - Rescale the input to make it best fit the model.\n",
        "    - The final image result will be based on this **Rescaled Face**. Use padding parameters to adjust the background space.\n",
        "    - **<font color=red>Solution to [Error: no face detected!]</font>**: VToonify uses dlib.get_frontal_face_detector but sometimes it fails to detect a face. You can try several times or use other images until a face is detected, then switch back to the original image.\n",
        "- For video input, further hit the **Rescale Video** button.\n",
        "    - The final video result will be based on this **Rescaled Video**. To avoid overload, video is cut to at most **100** frames for CPU, respectively.\n",
        "''')\n",
        "        with gr.Row():\n",
        "            with gr.Group():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown('''Choose the padding parameters.\n",
        "    ![example](https://raw.githubusercontent.com/williamyang1991/tmpfile/master/vtoonify/rescale.jpg)''')\n",
        "                    with gr.Row():\n",
        "                        top = gr.Slider(128,\n",
        "                                        256,\n",
        "                                        value=160,\n",
        "                                        step=8,\n",
        "                                        label='top')\n",
        "                    with gr.Row():\n",
        "                        bottom = gr.Slider(128,\n",
        "                                        256,\n",
        "                                        value=160,\n",
        "                                        step=8,\n",
        "                                        label='bottom')\n",
        "                    with gr.Row():\n",
        "                        left = gr.Slider(128,\n",
        "                                        256,\n",
        "                                        value=160,\n",
        "                                        step=8,\n",
        "                                        label='left')\n",
        "                    with gr.Row():\n",
        "                        right = gr.Slider(128,\n",
        "                                        256,\n",
        "                                        value=160,\n",
        "                                        step=8,\n",
        "                                        label='right')\n",
        "            with gr.Group():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown('''Input''')\n",
        "                    with gr.Row():\n",
        "                        input_image = gr.Image(label='Input Image')\n",
        "                    with gr.Row():\n",
        "                        preprocess_image_button = gr.Button('Rescale Image')\n",
        "                    with gr.Row():\n",
        "                        input_video = gr.Video(label='Input Video',\n",
        "                                               mirror_webcam=False)\n",
        "                    with gr.Row():\n",
        "                        preprocess_video0_button = gr.Button('Rescale First Frame')\n",
        "                        preprocess_video1_button = gr.Button('Rescale Video')\n",
        "\n",
        "            with gr.Group():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown('''View''')\n",
        "                    with gr.Row():\n",
        "                        input_info = gr.Textbox(label='Process Information', interactive=False, value='n.a.')\n",
        "                    with gr.Row():\n",
        "                        aligned_face = gr.Image(label='Rescaled Face',\n",
        "                                        type='numpy',\n",
        "                                        interactive=False)\n",
        "                        instyle = gr.State()\n",
        "                    with gr.Row():\n",
        "                        aligned_video = gr.Video(label='Rescaled Video',\n",
        "                                        interactive=False)\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                paths = ['./vtoonify/data/pexels-andrea-piacquadio-733872.jpg','./vtoonify/data/i5R8hbZFDdc.jpg','./vtoonify/data/yRpe13BHdKw.jpg','./vtoonify/data/ILip77SbmOE.jpg','./vtoonify/data/077436.jpg','./vtoonify/data/081680.jpg']\n",
        "                example_images = gr.Dataset(components=[input_image],\n",
        "                                        samples=[[path] for path in paths],\n",
        "                                           label='Image Examples')\n",
        "            with gr.Column():\n",
        "                #example_videos = gr.Dataset(components=[input_video], samples=[['./vtoonify/data/529.mp4']], type='values')\n",
        "                #to render video example on mouse hover/click\n",
        "                example_videos.render()\n",
        "                #to load sample video into input_video upon clicking on it\n",
        "                def load_examples(video):\n",
        "                    #print(\"****** inside load_example() ******\")\n",
        "                    #print(\"in_video is : \", video[0])\n",
        "                    return video[0]\n",
        "\n",
        "                example_videos.click(load_examples, example_videos, input_video)\n",
        "\n",
        "    with gr.Group():\n",
        "        gr.Markdown('''## Step 3 (Generate Style Transferred Image/Video)''')\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown('''\n",
        "                    - Adjust **Style Degree**.\n",
        "                    - Hit **Toonify!** to toonify one frame. Hit **VToonify!** to toonify full video.\n",
        "                        - Estimated time on 1600x1440 video of 300 frames: 1 hour (CPU); 2 mins (GPU)\n",
        "                    ''')\n",
        "                style_degree = gr.Slider(0,\n",
        "                                         1,\n",
        "                                         value=0.5,\n",
        "                                         step=0.05,\n",
        "                                         label='Style Degree')\n",
        "            with gr.Column():\n",
        "                gr.Markdown('''![example](https://raw.githubusercontent.com/williamyang1991/tmpfile/master/vtoonify/degree.jpg)\n",
        "                    ''')\n",
        "        with gr.Row():\n",
        "            output_info = gr.Textbox(label='Process Information', interactive=False, value='n.a.')\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    result_face = gr.Image(label='Result Image',\n",
        "                                        type='numpy',\n",
        "                                        interactive=False)\n",
        "                with gr.Row():\n",
        "                    toonify_button = gr.Button('Toonify!')\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    result_video = gr.Video(label='Result Video',\n",
        "                                        interactive=False)\n",
        "                with gr.Row():\n",
        "                    vtoonify_button = gr.Button('VToonify!')\n",
        "\n",
        "    gr.Markdown(ARTICLE)\n",
        "    gr.Markdown(FOOTER)\n",
        "\n",
        "    loadmodel_button.click(fn=model.load_model,\n",
        "                            inputs=[style_type],\n",
        "                            outputs=[exstyle, load_info])\n",
        "\n",
        "\n",
        "    style_type.change(fn=update_slider,\n",
        "                      inputs=style_type,\n",
        "                      outputs=style_degree)\n",
        "\n",
        "    preprocess_image_button.click(fn=model.detect_and_align_image,\n",
        "                            inputs=[input_image, top, bottom, left, right],\n",
        "                            outputs=[aligned_face, instyle, input_info])\n",
        "    preprocess_video0_button.click(fn=model.detect_and_align_video,\n",
        "                            inputs=[input_video, top, bottom, left, right],\n",
        "                            outputs=[aligned_face, instyle, input_info])\n",
        "    preprocess_video1_button.click(fn=model.detect_and_align_full_video,\n",
        "                            inputs=[input_video, top, bottom, left, right],\n",
        "                            outputs=[aligned_video, instyle, input_info])\n",
        "\n",
        "    toonify_button.click(fn=model.image_toonify,\n",
        "                            inputs=[aligned_face, instyle, exstyle, style_degree, style_type],\n",
        "                            outputs=[result_face, output_info])\n",
        "    vtoonify_button.click(fn=model.video_tooniy,\n",
        "                            inputs=[aligned_video, instyle, exstyle, style_degree, style_type],\n",
        "                            outputs=[result_video, output_info])\n",
        "    example_images.click(fn=set_example_image,\n",
        "                                 inputs=example_images,\n",
        "                                 outputs=example_images)"
      ],
      "metadata": {
        "id": "0Mz2MNcOgai6",
        "outputId": "8199e174-4dbd-457c-ae6d-ac9412770c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:163: UserWarning: The `mirror_webcam` parameter is deprecated. Please use the `webcam_options` parameter with a `gr.WebcamOptions` instance instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# launch a web demo, best open the public URL and view on new web page\n",
        "demo.launch(\n",
        "    debug=True,\n",
        ")"
      ],
      "metadata": {
        "id": "90dB2gmfgqOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6ebc4efa952f4c2a80b60d1847d2ae21",
            "e97c2d0297d742a6aa40680670650830",
            "21217694a433467d9c9e7c7d1534938f",
            "4d8b26b0663c4498a2e9cd2e718f81b4",
            "3f6e3d74c03443578364664ad8169c9e",
            "0db87c9ff4b04d598e12b19b76bdfd1c",
            "193bbafabc7b49f694975dfc750e81b7",
            "4039e31eac97444784ac1a80f79c8de5",
            "a86df05d4f424a9cae12979635ac0440",
            "28bdfaf1566c437985719cee7a298058",
            "6d6a194139ce48e1a7dfa74a4d1be3fb",
            "daeaf1dcc5cb404198cdb3b174e8ab9e",
            "b77d1746178241e3b88a06d237cf8127",
            "76e07ebc5162430c80aa4df071d47d22",
            "cc9937b93c5e42efbf470c0c9fe5ed92",
            "8d6f2d3574cd4f1e96ac9cffe349cc2c",
            "5e7e381a242e4cdb89cf605c132ac06c",
            "94a6b9a9c24f4b1cb6bb6cf2ee9bece7",
            "6f7348034c3e43ea8b64bbad307d6719",
            "3c709ee3f6404ab2a1b4e67b8fe97714",
            "1c060c7e55104484bcbb9908dacd8a0e",
            "6ae56d281cd94c49b86ecb865307b096",
            "5f18b25d01994c3984c652ffb0efca86",
            "fa53164475d0486db38aef4a6d2ede1c",
            "19719ee8fbaa429290dd9d527d0903ea",
            "7219514892bb43029a093df67bd6c46d",
            "e5f8a37f78b84a97b04020a41905ef9d",
            "455d5fc2842d4f4985c3f7ab80add500",
            "b6cf24bc74494772aa5dd9a49db19dad",
            "e3a52b6c2a0742bf8c4c467690abb0a6",
            "51e1e8af0b864fd48d381a8c6e3e7b6b",
            "fba843cdee664cac964f6d6b6c1a295d",
            "526d1f36d0874908b1b86ff339482711",
            "a6e82f8473c345e587d177d5eb62a9b7",
            "0af6f951a8084b1fb214f399a58c1b09",
            "697438cac02d4ee3840e3c0906f0fddd",
            "03e0125c01604cc29c659f046a8a9dd5",
            "7b36edeb9065485eabce728e221d7545",
            "6588d8fff83b444ba55bbfc6c82ef2c8",
            "5c48c51dea864a2c9abacb2db2fcbbdc",
            "f4c1ec365e8e41bb91f78ee35c57e14a",
            "24261117fbba4f86975cc82b40a0b2be",
            "743765c99e8f409c933d81c64676a268",
            "268bdd3d22a043d5a4aa16477ccb1a75",
            "9e7d98c0effb4e84aa15f4c12144981c",
            "eb87c5e849204dac83c300731047ca1d",
            "5d2b60ae8c404caa9a6d0934470964e8",
            "bae01ac4a40e471c933849c8df99135c",
            "a3147eeff721482bb38b592148730a94",
            "73d1bd1aba6e4d0b99670d61acb206ff",
            "e07e1899dee14a3aabe463b8cdb57a34",
            "7e04f36709a344c888d778aee3d83b52",
            "832934c11c36485b92b174fa11ab5e6d",
            "6bffd3706d7041a9939ff326f847bed3",
            "b0a840de38bb4b9387f813d43428ecde"
          ]
        },
        "outputId": "2a38eaed-d6be-48af-e9fa-569e76375e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e59c4ccd4fa937e221.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e59c4ccd4fa937e221.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: no face detected!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Toonify using batch size of 4 on 1280x1280 video of 29 frames with style of cartoon1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Toonify using batch size of 3 on 1760x1728 video of 217 frames with style of cartoon1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "models/vtoonify_d_arcane/vtoonify_s077_d(…):   0%|          | 0.00/667M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ebc4efa952f4c2a80b60d1847d2ae21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "models/vtoonify_d_arcane/exstyle_code.np(…):   0%|          | 0.00/3.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daeaf1dcc5cb404198cdb3b174e8ab9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Toonify using batch size of 3 on 1536x1536 video of 87 frames with style of arcane2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "models/vtoonify_d_illustration/vtoonify_(…):   0%|          | 0.00/667M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f18b25d01994c3984c652ffb0efca86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "models/vtoonify_d_illustration/exstyle_c(…):   0%|          | 0.00/5.76M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6e82f8473c345e587d177d5eb62a9b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Toonify using batch size of 3 on 1536x1536 video of 87 frames with style of illustration5-d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:355: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "models/vtoonify_d_illustration/vtoonify_(…):   0%|          | 0.00/667M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e7d98c0effb4e84aa15f4c12144981c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can close the web demo by running\n",
        "demo.close()"
      ],
      "metadata": {
        "id": "s29j3OxJgrgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART II - Style Transfer with specialized VToonify-D model"
      ],
      "metadata": {
        "id": "KbWEFjJi8DRW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WeAGqJOzwMT"
      },
      "source": [
        "code is mainly modified from [pixel2style2pixel](https://github.com/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uuviq3qQkUFy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "os.chdir('../')\n",
        "CODE_DIR = 'VToonify'\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ6XEmlHlXbk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/williamyang1991/VToonify.git $CODE_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3Hc2FYAzwMW"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23baccYQlU9E"
      },
      "outputs": [],
      "source": [
        "os.chdir(f'./{CODE_DIR}')\n",
        "MODEL_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'checkpoint')\n",
        "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'data')\n",
        "OUT_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d13v7In0kTJn"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "import dlib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from model.vtoonify import VToonify\n",
        "from model.bisenet.model import BiSeNet\n",
        "from model.encoder.align_all_parallel import align_face\n",
        "from util import save_image, load_image, visualize, load_psp_standalone, get_video_crop_parameter, tensor2cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSnjlBZOkTJ0"
      },
      "outputs": [],
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../checkpoint/. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = MODEL_DIR\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    \"encoder\": {\"id\": \"1NgI4mPkboYvYw3MWcdUaQhkr0OWgs9ej\", \"name\": \"encoder.pt\"},\n",
        "    \"faceparsing\": {\"id\": \"1jY0mTjVB8njDh6e0LP_2UxuRK3MnjoIR\", \"name\": \"faceparsing.pth\"},\n",
        "    \"arcane_exstyle\": {\"id\": \"1TC67wRJkdmNRZTqYMUEFkrhWRKKZW40c\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"caricature_exstyle\": {\"id\": \"1xr9sx_WmRYJ4qHGTtdVQCSxSo4HP3-ip\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"cartoon_exstyle\": {\"id\": \"1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"pixar_exstyle\": {\"id\": \"1yTaKuSrL7I0i0RYEEK5XD6GI-y5iNUbj\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"arcane000\": {\"id\": \"1pF4fJ8acmawMsjjXo4HXRIOXeZR8jLVh\", \"name\": \"generator.pt\"},\n",
        "    \"arcane077\": {\"id\": \"16rLTF2oC0ZeurnM6hjrfrc8BxtW8P8Qf\", \"name\": \"generator.pt\"},\n",
        "    \"caricature039\": {\"id\": \"1C1E4WEoDWzl0nAxR9okKffFmlMOENbeF\", \"name\": \"generator.pt\"},\n",
        "    \"caricature068\": {\"id\": \"1B1ko1x8fX2aJ4BYCL12AnknVAi3qQc8W\", \"name\": \"generator.pt\"},\n",
        "    \"cartoon026\": {\"id\": \"1YJYODh_vEyUrL0q02okjcicpJhdYY8An\", \"name\": \"generator.pt\"},\n",
        "    \"cartoon299\": {\"id\": \"101qMUMfcI2qDxEbfCBt5mOg2aSqdTaIt\", \"name\": \"generator.pt\"},\n",
        "    \"pixar052\": {\"id\": \"16j_l1x0DD0PjwO8YdplAk69sh3-v95rr\", \"name\": \"generator.pt\"},\n",
        "    \"cartoon\": {\"id\": \"11s0hwhZWTLacMAzZH4OU-o3Qkp54h30J\", \"name\": \"generator.pt\"},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFJJLLP5zwMZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRjtz6uLkTJs"
      },
      "source": [
        "## Step 1: Select Style Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaetIVq8zwMa"
      },
      "outputs": [],
      "source": [
        "#@title Select a style type { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "style_type = \"cartoon026\" #@param [\"cartoon026\", \"cartoon299\", \"arcane000\", \"arcane077\", \"pixar052\", \"caricature039\", \"caricature068\"]\n",
        "\n",
        "\"\"\"\n",
        "cartoon026:      balanced\n",
        "cartoon299:      big eyes\n",
        "arcane000:       for female\n",
        "arcane077:       for male\n",
        "pixar052:\n",
        "caricature039:   big mouth\n",
        "caricature068:   balanced\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etDz82xkTJz"
      },
      "source": [
        "## Step 2: Download Pretrained Models\n",
        "As part of this repository, we provide pretrained models. We'll download the model and save them to the folder `../checkpoint/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLLXjePvzwMb"
      },
      "outputs": [],
      "source": [
        "# download pSp encoder and face parsinf network\n",
        "path = MODEL_PATHS[\"encoder\"]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "!{download_command}\n",
        "path = MODEL_PATHS[\"faceparsing\"]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "!{download_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ31J_m7kTJ8"
      },
      "outputs": [],
      "source": [
        "# download vtoonify\n",
        "path = MODEL_PATHS[style_type]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = style_type + '_' + path[\"name\"])\n",
        "!{download_command}\n",
        "# download extrinsic style code\n",
        "path = MODEL_PATHS[style_type[:-3]+'_exstyle']\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = style_type[:-3] + '_' + path[\"name\"])\n",
        "!{download_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAWrUehTkTKJ"
      },
      "source": [
        "## Step 3: Load Pretrained Model\n",
        "We assume that you have downloaded all relevant models and placed them in the directory defined by the above dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBgNcA7XzwMb"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5,0.5,0.5]),\n",
        "    ])\n",
        "\n",
        "vtoonify = VToonify(backbone = 'dualstylegan')\n",
        "vtoonify.load_state_dict(torch.load(os.path.join(MODEL_DIR, style_type+'_generator.pt'), map_location=lambda storage, loc: storage)['g_ema'])\n",
        "vtoonify.to(device)\n",
        "\n",
        "parsingpredictor = BiSeNet(n_classes=19)\n",
        "parsingpredictor.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'faceparsing.pth'), map_location=lambda storage, loc: storage))\n",
        "parsingpredictor.to(device).eval()\n",
        "\n",
        "modelname = './checkpoint/shape_predictor_68_face_landmarks.dat'\n",
        "if not os.path.exists(modelname):\n",
        "    import wget, bz2\n",
        "    wget.download('http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2', modelname+'.bz2')\n",
        "    zipfile = bz2.BZ2File(modelname+'.bz2')\n",
        "    data = zipfile.read()\n",
        "    open(modelname, 'wb').write(data)\n",
        "landmarkpredictor = dlib.shape_predictor(modelname)\n",
        "\n",
        "pspencoder = load_psp_standalone(os.path.join(MODEL_DIR, 'encoder.pt'), device)\n",
        "\n",
        "exstyles = np.load(os.path.join(MODEL_DIR, style_type[:-3]+'_exstyle_code.npy'), allow_pickle='TRUE').item()\n",
        "stylename = list(exstyles.keys())[int(style_type[-3:])]\n",
        "exstyle = torch.tensor(exstyles[stylename]).to(device)\n",
        "with torch.no_grad():\n",
        "    exstyle = vtoonify.zplus2wplus(exstyle)\n",
        "\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4weLFoPbkTKZ"
      },
      "source": [
        "## Step 4: Image Toonification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6oqf8JwzK0K"
      },
      "source": [
        "### Visualize and Rescale Input\n",
        "We rescale the input image to make it fit our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2H9zFLJkTKa"
      },
      "outputs": [],
      "source": [
        "image_path = './data/077436.jpg'\n",
        "original_image = load_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lbLKtl-kTKc"
      },
      "outputs": [],
      "source": [
        "visualize(original_image[0], 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ9Ce1aYzmFF"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread(image_path)\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "scale = 1\n",
        "kernel_1d = np.array([[0.125],[0.375],[0.375],[0.125]])\n",
        "# We detect the face in the image, and resize the image so that the eye distance is 64 pixels.\n",
        "# Centered on the eyes, we crop the image to almost 400x400 (based on args.padding).\n",
        "paras = get_video_crop_parameter(frame, landmarkpredictor, padding=[200,200,200,200])\n",
        "if paras is not None:\n",
        "    h,w,top,bottom,left,right,scale = paras\n",
        "    H, W = int(bottom-top), int(right-left)\n",
        "    # for HR image, we apply gaussian blur to it to avoid over-sharp stylization results\n",
        "    if scale <= 0.75:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    if scale <= 0.375:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    frame = cv2.resize(frame, (w, h))[top:bottom, left:right]\n",
        "    x = transform(frame).unsqueeze(dim=0).to(device)\n",
        "else:\n",
        "    print('no face detected!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUBAfodh5PaM"
      },
      "outputs": [],
      "source": [
        "visualize(x[0].cpu(), 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0BmXzu1kTKg"
      },
      "source": [
        "### Perform Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnCKxP8FzwMd"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    I = align_face(frame, landmarkpredictor)\n",
        "    I = transform(I).unsqueeze(dim=0).to(device)\n",
        "    s_w = pspencoder(I)\n",
        "    s_w = vtoonify.zplus2wplus(s_w)\n",
        "    s_w[:,:7] = exstyle[:,:7]\n",
        "    # parsing network works best on 512x512 images, so we predict parsing maps on upsmapled frames\n",
        "    # followed by downsampling the parsing maps\n",
        "    x_p = F.interpolate(parsingpredictor(2*(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)))[0],\n",
        "                        scale_factor=0.5, recompute_scale_factor=False).detach()\n",
        "    # we give parsing maps lower weight (1/16)\n",
        "    inputs = torch.cat((x, x_p/16.), dim=1)\n",
        "    # d_s has no effect when backbone is toonify\n",
        "    y_tilde = vtoonify(inputs, s_w.repeat(inputs.size(0), 1, 1), d_s = 0.5)\n",
        "    y_tilde = torch.clamp(y_tilde, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYzQZT8czwMe"
      },
      "outputs": [],
      "source": [
        "visualize(y_tilde[0].cpu(), 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjCvUNrWzwMe"
      },
      "source": [
        "## Step 5: Video Toonification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbsH8H3nzwMe"
      },
      "source": [
        "### Visualize and Rescale Input\n",
        "We rescale the input video to make it fit our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V38qIi7zwMe"
      },
      "outputs": [],
      "source": [
        "video_path = './data/529.mp4'\n",
        "video_cap = cv2.VideoCapture(video_path)\n",
        "num = int(video_cap.get(7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWG8-hsAzwMe"
      },
      "outputs": [],
      "source": [
        "success, frame = video_cap.read()\n",
        "if success == False:\n",
        "    assert('load video frames error')\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kec029XTzwMf"
      },
      "outputs": [],
      "source": [
        "visualize(transform(frame), 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9FAXp2xzwMf"
      },
      "outputs": [],
      "source": [
        "scale = 1\n",
        "kernel_1d = np.array([[0.125],[0.375],[0.375],[0.125]])\n",
        "# We proprocess the video by detecting the face in the first frame,\n",
        "# and resizing the frame so that the eye distance is 64 pixels.\n",
        "# Centered on the eyes, we crop the first frame to almost 400x400 (based on args.padding).\n",
        "# All other frames use the same resizing and cropping parameters as the first frame.\n",
        "paras = get_video_crop_parameter(frame, landmarkpredictor, padding=[200,200,200,200])\n",
        "if paras is None:\n",
        "    print('no face detected!')\n",
        "else:\n",
        "    h,w,top,bottom,left,right,scale = paras\n",
        "    H, W = int(bottom-top), int(right-left)\n",
        "# for HR video, we apply gaussian blur to the frames to avoid flickers caused by bilinear downsampling\n",
        "# this can also prevent over-sharp stylization results.\n",
        "if scale <= 0.75:\n",
        "    frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "if scale <= 0.375:\n",
        "    frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "frame = cv2.resize(frame, (w, h))[top:bottom, left:right]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGA_os5gzwMf"
      },
      "outputs": [],
      "source": [
        "visualize(transform(frame), 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF_Uk0lKzwMf"
      },
      "source": [
        "### Perform Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG1FxtPzzwMf"
      },
      "outputs": [],
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "videoWriter = cv2.VideoWriter(os.path.join(OUT_DIR, 'result.mp4'), fourcc, video_cap.get(5), (4*W, 4*H))\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30bmxfpbzwMf"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    batch_frames = []\n",
        "    for i in tqdm(range(num)):\n",
        "        if i == 0:\n",
        "            I = align_face(frame, landmarkpredictor)\n",
        "            I = transform(I).unsqueeze(dim=0).to(device)\n",
        "            s_w = pspencoder(I)\n",
        "            s_w = vtoonify.zplus2wplus(s_w)\n",
        "            s_w[:,:7] = exstyle[:,:7]\n",
        "        else:\n",
        "            success, frame = video_cap.read()\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            if scale <= 0.75:\n",
        "                frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "            if scale <= 0.375:\n",
        "                frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "            frame = cv2.resize(frame, (w, h))[top:bottom, left:right]\n",
        "\n",
        "        batch_frames += [transform(frame).unsqueeze(dim=0).to(device)]\n",
        "\n",
        "        if len(batch_frames) == batch_size or (i+1) == num:\n",
        "            x = torch.cat(batch_frames, dim=0)\n",
        "            batch_frames = []\n",
        "            # parsing network works best on 512x512 images, so we predict parsing maps on upsmapled frames\n",
        "            # followed by downsampling the parsing maps\n",
        "            x_p = F.interpolate(parsingpredictor(2*(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)))[0],\n",
        "                            scale_factor=0.5, recompute_scale_factor=False).detach()\n",
        "            # we give parsing maps lower weight (1/16)\n",
        "            inputs = torch.cat((x, x_p/16.), dim=1)\n",
        "            # d_s has no effect when backbone is toonify\n",
        "            y_tilde = vtoonify(inputs, s_w.repeat(inputs.size(0), 1, 1), d_s = 0.5)\n",
        "            y_tilde = torch.clamp(y_tilde, -1, 1)\n",
        "            for k in range(y_tilde.size(0)):\n",
        "                videoWriter.write(tensor2cv2(y_tilde[k].cpu()))\n",
        "videoWriter.release()\n",
        "video_cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJeDEh-TzwMg"
      },
      "outputs": [],
      "source": [
        "viz = torchvision.utils.make_grid(y_tilde, 2, 2)\n",
        "visualize(viz.cpu(), 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF3boImzzwMg"
      },
      "source": [
        "### Find the stylized video in `./output/result.mp4`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt9fQiLozwMg"
      },
      "source": [
        "# PART III - Style control with VToonify-Dsd model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hWqNQHOzwMg"
      },
      "source": [
        "## Step 1: Download Pretrained Models\n",
        "As part of this repository, we provide pretrained models. We'll download the model and save them to the folder `../checkpoint/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1UVTjmVzwMh"
      },
      "outputs": [],
      "source": [
        "# if you haved downloaded the encoder and faceparsing model in PART I, skip this step\n",
        "if False:\n",
        "    path = MODEL_PATHS[\"encoder\"]\n",
        "    download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "    !{download_command}\n",
        "    path = MODEL_PATHS[\"faceparsing\"]\n",
        "    download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "    !{download_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R49HXW3KzwMh"
      },
      "outputs": [],
      "source": [
        "# download the style code and the vtoonify-Dsd\n",
        "path = MODEL_PATHS['cartoon_exstyle']\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = 'cartoon_exstyle_code.npy')\n",
        "!{download_command}\n",
        "path = MODEL_PATHS['cartoon']\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = 'cartoon_generator.pt')\n",
        "!{download_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju-b8ivNzwMh"
      },
      "source": [
        "## Step 2: Load Pretrained Model\n",
        "We assume that you have downloaded all relevant models and placed them in the directory defined by the above dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FRjygi8zwMh"
      },
      "outputs": [],
      "source": [
        "# if you haved load the models in PART I, skip this step, or set False to True\n",
        "if False:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5,0.5,0.5]),\n",
        "        ])\n",
        "\n",
        "    parsingpredictor = BiSeNet(n_classes=19)\n",
        "    parsingpredictor.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'faceparsing.pth'), map_location=lambda storage, loc: storage))\n",
        "    parsingpredictor.to(device).eval()\n",
        "\n",
        "    modelname = './checkpoint/shape_predictor_68_face_landmarks.dat'\n",
        "    if not os.path.exists(modelname):\n",
        "        wget.download('http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2', modelname+'.bz2')\n",
        "        zipfile = bz2.BZ2File(modelname+'.bz2')\n",
        "        data = zipfile.read()\n",
        "        open(modelname, 'wb').write(data)\n",
        "    landmarkpredictor = dlib.shape_predictor(modelname)\n",
        "\n",
        "    pspencoder = load_psp_standalone(os.path.join(MODEL_DIR, 'encoder.pt'), device)\n",
        "\n",
        "vtoonify = VToonify(backbone = 'dualstylegan')\n",
        "vtoonify.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'cartoon_generator.pt'), map_location=lambda storage, loc: storage)['g_ema'])\n",
        "vtoonify.to(device)\n",
        "\n",
        "exstyles = np.load(os.path.join(MODEL_DIR, 'cartoon_exstyle_code.npy'), allow_pickle='TRUE').item()\n",
        "styles = []\n",
        "with torch.no_grad():\n",
        "    for stylename in exstyles.keys():\n",
        "        exstyle = torch.tensor(exstyles[stylename]).to(device)\n",
        "        exstyle = vtoonify.zplus2wplus(exstyle)\n",
        "        styles += [exstyle]\n",
        "exstyles = torch.cat(styles, dim=0)\n",
        "\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skayaztpzwMh"
      },
      "source": [
        "## Step 3: Image Toonification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYcmhop8zwMh"
      },
      "source": [
        "### Visualize and Rescale Input\n",
        "We rescale the input image to make it fit our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9x591jNzwMi"
      },
      "outputs": [],
      "source": [
        "image_path = './data/077436.jpg'\n",
        "original_image = load_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKXXNqekzwMi"
      },
      "outputs": [],
      "source": [
        "visualize(original_image[0], 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96d102HjzwMi"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread(image_path)\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "scale = 1\n",
        "kernel_1d = np.array([[0.125],[0.375],[0.375],[0.125]])\n",
        "# We detect the face in the image, and resize the image so that the eye distance is 64 pixels.\n",
        "# Centered on the eyes, we crop the image to almost 400x400 (based on args.padding).\n",
        "paras = get_video_crop_parameter(frame, landmarkpredictor, padding=[200,200,200,200])\n",
        "if paras is not None:\n",
        "    h,w,top,bottom,left,right,scale = paras\n",
        "    H, W = int(bottom-top), int(right-left)\n",
        "    # for HR image, we apply gaussian blur to it to avoid over-sharp stylization results\n",
        "    if scale <= 0.75:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    if scale <= 0.375:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    frame = cv2.resize(frame, (w, h))[top:bottom, left:right]\n",
        "    x = transform(frame).unsqueeze(dim=0).to(device)\n",
        "else:\n",
        "    print('no face detected!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW8sPnwkzwMi"
      },
      "outputs": [],
      "source": [
        "visualize(x[0].cpu(), 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iMk0ZuazwMi"
      },
      "source": [
        "### Select style image\n",
        "\n",
        "Select the style index (the mapping between index and style image is defined [here](https://github.com/williamyang1991/DualStyleGAN/blob/main/doc_images/cartoon_overview.jpg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3IfNjdHzwMi"
      },
      "outputs": [],
      "source": [
        "style_id = [8, 26, 64, 153, 299]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AhjbJJ1zwMj"
      },
      "source": [
        "### Style transfer with different cartoon structure styles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5POMJ5YkTKl"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    I = align_face(frame, landmarkpredictor)\n",
        "    I = transform(I).unsqueeze(dim=0).to(device)\n",
        "    s_w = pspencoder(I)\n",
        "    s_w = vtoonify.zplus2wplus(s_w).repeat(len(style_id), 1, 1)\n",
        "    s_w[:,:7] = exstyles[style_id,:7]\n",
        "    x = x.repeat(len(style_id), 1, 1, 1)\n",
        "    # parsing network works best on 512x512 images, so we predict parsing maps on upsmapled frames\n",
        "    # followed by downsampling the parsing maps\n",
        "    x_p = F.interpolate(parsingpredictor(2*(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)))[0],\n",
        "                        scale_factor=0.5, recompute_scale_factor=False).detach()\n",
        "    # we give parsing maps lower weight (1/16)\n",
        "    inputs = torch.cat((x, x_p/16.), dim=1)\n",
        "    # d_s has no effect when backbone is toonify\n",
        "    y_tilde = vtoonify(inputs, s_w, d_s = 0.6)\n",
        "    y_tilde = torch.clamp(y_tilde, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsHq90J1zwMj"
      },
      "outputs": [],
      "source": [
        "viz = torchvision.utils.make_grid(y_tilde, 5, 2)\n",
        "visualize(viz.cpu(), 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HJ-gtKrzwMj"
      },
      "source": [
        "### Navigation with different style degree to achieve flexible style manipulation\n",
        "\n",
        "Users are suggested to try different style degrees to find the ideal results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Q9nk7M0zwMj"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "with torch.no_grad():\n",
        "    for i in range(5):\n",
        "        d_s = i / 4.0\n",
        "        y_tilde = vtoonify(inputs, s_w, d_s = d_s)\n",
        "        y_tilde = torch.clamp(y_tilde, -1, 1)\n",
        "        results += [y_tilde.cpu()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vis = torchvision.utils.make_grid(torch.cat(results, dim=0), 5, 2)\n",
        "visualize(vis, 120)"
      ],
      "metadata": {
        "id": "qMC8_NkuALeF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aF3boImzzwMg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "psp_env",
      "language": "python",
      "name": "psp_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ebc4efa952f4c2a80b60d1847d2ae21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e97c2d0297d742a6aa40680670650830",
              "IPY_MODEL_21217694a433467d9c9e7c7d1534938f",
              "IPY_MODEL_4d8b26b0663c4498a2e9cd2e718f81b4"
            ],
            "layout": "IPY_MODEL_3f6e3d74c03443578364664ad8169c9e"
          }
        },
        "e97c2d0297d742a6aa40680670650830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db87c9ff4b04d598e12b19b76bdfd1c",
            "placeholder": "​",
            "style": "IPY_MODEL_193bbafabc7b49f694975dfc750e81b7",
            "value": "models/vtoonify_d_arcane/vtoonify_s077_d(…): 100%"
          }
        },
        "21217694a433467d9c9e7c7d1534938f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4039e31eac97444784ac1a80f79c8de5",
            "max": 666594870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a86df05d4f424a9cae12979635ac0440",
            "value": 666594870
          }
        },
        "4d8b26b0663c4498a2e9cd2e718f81b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28bdfaf1566c437985719cee7a298058",
            "placeholder": "​",
            "style": "IPY_MODEL_6d6a194139ce48e1a7dfa74a4d1be3fb",
            "value": " 667M/667M [00:15&lt;00:00, 70.0MB/s]"
          }
        },
        "3f6e3d74c03443578364664ad8169c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db87c9ff4b04d598e12b19b76bdfd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "193bbafabc7b49f694975dfc750e81b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4039e31eac97444784ac1a80f79c8de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86df05d4f424a9cae12979635ac0440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28bdfaf1566c437985719cee7a298058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6a194139ce48e1a7dfa74a4d1be3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daeaf1dcc5cb404198cdb3b174e8ab9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b77d1746178241e3b88a06d237cf8127",
              "IPY_MODEL_76e07ebc5162430c80aa4df071d47d22",
              "IPY_MODEL_cc9937b93c5e42efbf470c0c9fe5ed92"
            ],
            "layout": "IPY_MODEL_8d6f2d3574cd4f1e96ac9cffe349cc2c"
          }
        },
        "b77d1746178241e3b88a06d237cf8127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7e381a242e4cdb89cf605c132ac06c",
            "placeholder": "​",
            "style": "IPY_MODEL_94a6b9a9c24f4b1cb6bb6cf2ee9bece7",
            "value": "models/vtoonify_d_arcane/exstyle_code.np(…): 100%"
          }
        },
        "76e07ebc5162430c80aa4df071d47d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f7348034c3e43ea8b64bbad307d6719",
            "max": 3694721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c709ee3f6404ab2a1b4e67b8fe97714",
            "value": 3694721
          }
        },
        "cc9937b93c5e42efbf470c0c9fe5ed92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c060c7e55104484bcbb9908dacd8a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_6ae56d281cd94c49b86ecb865307b096",
            "value": " 3.69M/3.69M [00:02&lt;00:00, 1.37MB/s]"
          }
        },
        "8d6f2d3574cd4f1e96ac9cffe349cc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7e381a242e4cdb89cf605c132ac06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a6b9a9c24f4b1cb6bb6cf2ee9bece7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f7348034c3e43ea8b64bbad307d6719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c709ee3f6404ab2a1b4e67b8fe97714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c060c7e55104484bcbb9908dacd8a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae56d281cd94c49b86ecb865307b096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f18b25d01994c3984c652ffb0efca86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa53164475d0486db38aef4a6d2ede1c",
              "IPY_MODEL_19719ee8fbaa429290dd9d527d0903ea",
              "IPY_MODEL_7219514892bb43029a093df67bd6c46d"
            ],
            "layout": "IPY_MODEL_e5f8a37f78b84a97b04020a41905ef9d"
          }
        },
        "fa53164475d0486db38aef4a6d2ede1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455d5fc2842d4f4985c3f7ab80add500",
            "placeholder": "​",
            "style": "IPY_MODEL_b6cf24bc74494772aa5dd9a49db19dad",
            "value": "models/vtoonify_d_illustration/vtoonify_(…): 100%"
          }
        },
        "19719ee8fbaa429290dd9d527d0903ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a52b6c2a0742bf8c4c467690abb0a6",
            "max": 666594870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51e1e8af0b864fd48d381a8c6e3e7b6b",
            "value": 666594870
          }
        },
        "7219514892bb43029a093df67bd6c46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba843cdee664cac964f6d6b6c1a295d",
            "placeholder": "​",
            "style": "IPY_MODEL_526d1f36d0874908b1b86ff339482711",
            "value": " 667M/667M [00:22&lt;00:00, 45.4MB/s]"
          }
        },
        "e5f8a37f78b84a97b04020a41905ef9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "455d5fc2842d4f4985c3f7ab80add500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6cf24bc74494772aa5dd9a49db19dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3a52b6c2a0742bf8c4c467690abb0a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51e1e8af0b864fd48d381a8c6e3e7b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fba843cdee664cac964f6d6b6c1a295d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526d1f36d0874908b1b86ff339482711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6e82f8473c345e587d177d5eb62a9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0af6f951a8084b1fb214f399a58c1b09",
              "IPY_MODEL_697438cac02d4ee3840e3c0906f0fddd",
              "IPY_MODEL_03e0125c01604cc29c659f046a8a9dd5"
            ],
            "layout": "IPY_MODEL_7b36edeb9065485eabce728e221d7545"
          }
        },
        "0af6f951a8084b1fb214f399a58c1b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6588d8fff83b444ba55bbfc6c82ef2c8",
            "placeholder": "​",
            "style": "IPY_MODEL_5c48c51dea864a2c9abacb2db2fcbbdc",
            "value": "models/vtoonify_d_illustration/exstyle_c(…): 100%"
          }
        },
        "697438cac02d4ee3840e3c0906f0fddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c1ec365e8e41bb91f78ee35c57e14a",
            "max": 5764913,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24261117fbba4f86975cc82b40a0b2be",
            "value": 5764913
          }
        },
        "03e0125c01604cc29c659f046a8a9dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743765c99e8f409c933d81c64676a268",
            "placeholder": "​",
            "style": "IPY_MODEL_268bdd3d22a043d5a4aa16477ccb1a75",
            "value": " 5.76M/5.76M [00:02&lt;00:00, 2.10MB/s]"
          }
        },
        "7b36edeb9065485eabce728e221d7545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6588d8fff83b444ba55bbfc6c82ef2c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c48c51dea864a2c9abacb2db2fcbbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4c1ec365e8e41bb91f78ee35c57e14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24261117fbba4f86975cc82b40a0b2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "743765c99e8f409c933d81c64676a268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268bdd3d22a043d5a4aa16477ccb1a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e7d98c0effb4e84aa15f4c12144981c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb87c5e849204dac83c300731047ca1d",
              "IPY_MODEL_5d2b60ae8c404caa9a6d0934470964e8",
              "IPY_MODEL_bae01ac4a40e471c933849c8df99135c"
            ],
            "layout": "IPY_MODEL_a3147eeff721482bb38b592148730a94"
          }
        },
        "eb87c5e849204dac83c300731047ca1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d1bd1aba6e4d0b99670d61acb206ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e07e1899dee14a3aabe463b8cdb57a34",
            "value": "models/vtoonify_d_illustration/vtoonify_(…): 100%"
          }
        },
        "5d2b60ae8c404caa9a6d0934470964e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e04f36709a344c888d778aee3d83b52",
            "max": 666594870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_832934c11c36485b92b174fa11ab5e6d",
            "value": 666594870
          }
        },
        "bae01ac4a40e471c933849c8df99135c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bffd3706d7041a9939ff326f847bed3",
            "placeholder": "​",
            "style": "IPY_MODEL_b0a840de38bb4b9387f813d43428ecde",
            "value": " 667M/667M [00:16&lt;00:00, 28.3MB/s]"
          }
        },
        "a3147eeff721482bb38b592148730a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d1bd1aba6e4d0b99670d61acb206ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07e1899dee14a3aabe463b8cdb57a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e04f36709a344c888d778aee3d83b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832934c11c36485b92b174fa11ab5e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bffd3706d7041a9939ff326f847bed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a840de38bb4b9387f813d43428ecde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}